apiVersion: batch/v1
kind: CronJob
metadata:
  annotations: {}
  labels:
    cronjob: kubermatic-cluster-cleanup-kubegame
  name: kubermatic-cluster-cleanup-kubegame
  namespace: kube-system
spec:
  concurrencyPolicy: Forbid
  failedJobsHistoryLimit: 3
  jobTemplate:
    metadata:
      creationTimestamp: null
    spec:
      template:
        metadata:
#          annotations:
#            prometheus.io/scrape: "false"
          creationTimestamp: null
          labels:
            cronjob: kubermatic-cluster-cleanup-kubegame
        spec:
          containers:
            - args:
                - |-
                  # Deliberately do not use euo pipefail, we want to clean up
                  # as much as possible even if we encounter an error
                  set -x
                  echodate() { echo "$(date) $@"; }
                  echodate "Starting to clean up"
                  
                  #max 90 tries => 15min for one cluster
                  maxcount=1 
                  for i in `kubectl get cluster  -l project-id=9596h8bgw5 --no-headers | awk '{print $1}'`; do
                      count=0

                      kubectl delete cluster $i
                      until kubectl get cluster $i 2>&1| grep -q NotFound  ||  [ $count -ge $maxcount ] ; do
                           echodate "Cluster $i is still been deleted, waiting for it to be cleaned up ... ($count / $maxcount)"
                           ((count=count+1))
                           sleep 10s
                      done
                      echodate "Cluster $i has been deleted"
                  done
                  echodate "Cluster cleanup has been completed"
              command:
                - /bin/bash
                - -c
              image: quay.io/kubermatic/util:2.3.0
              imagePullPolicy: IfNotPresent
              name: cluster-cleanup
              resources: {}
              terminationMessagePath: /dev/termination-log
              terminationMessagePolicy: File
          dnsPolicy: ClusterFirst
          restartPolicy: Never
          schedulerName: default-scheduler
          securityContext: {}
          serviceAccountName: kubermatic-cluster-cleanup-kubegame
          terminationGracePeriodSeconds: 30
  schedule: '*/5 * * * *'
  startingDeadlineSeconds: 30
  successfulJobsHistoryLimit: 3
  suspend: true
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  annotations: {}
  name: kubermatic:clusters:cleanup
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: kubermatic:clusters:cleanup
subjects:
  - kind: ServiceAccount
    name: kubermatic-cluster-cleanup-kubegame
    namespace: kube-system
---
apiVersion: v1
kind: ServiceAccount
metadata:
  annotations: {}
  name: kubermatic-cluster-cleanup-kubegame
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  annotations: {}
  name: kubermatic:clusters:cleanup
rules:
  - apiGroups:
      - kubermatic.k8s.io
      - kubermatic.k8c.io
    resources:
      - clusters
    verbs:
      - list
      - get
      - patch
      - delete
  - apiGroups:
      - kubermatic.k8s.io
      - kubermatic.k8c.io
    resources:
      - addons
    verbs:
      - list
      - get
      - patch
      - delete
  - apiGroups:
      - ""
    resources:
      - namespaces
    verbs:
      - get
      - list
      - watch
